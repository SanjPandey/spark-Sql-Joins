{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 882
        },
        "id": "pZQtvTgdPuiQ",
        "outputId": "534f87d8-04b6-407b-e26c-ad42799ffba7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [814 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,077 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,369 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [2,251 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,748 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,333 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,032 kB]\n",
            "Fetched 11.9 MB in 4s (3,045 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "45 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "tar: spark-3.2.1-bin-hadoop3.2.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=f03e3beaa684b550f9e52047e096a3a8b79367ab44e461ca64221236824465d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x78d9ae703040>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://be2fab254089:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Our First Spark Example</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#Check this site for the latest download link https://www.apache.org/dyn/closer.lua/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j\n",
        "\n",
        "import os\n",
        "import sys\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n",
        "\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()\n",
        "\n",
        "import pyspark\n",
        "\n",
        "from pyspark.sql import DataFrame, SparkSession\n",
        "from typing import List\n",
        "import pyspark.sql.types as T\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "spark= SparkSession \\\n",
        "       .builder \\\n",
        "       .appName(\"Our First Spark Example\") \\\n",
        "       .getOrCreate()\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.serve_kernel_port_as_window(4040, path='/jobs/index.html')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "S41IKfvJQAHf",
        "outputId": "4a78ffa1-637f-4107-ae53-4df4fb55d38f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, text, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port);\n",
              "    const anchor = document.createElement('a');\n",
              "    anchor.href = new URL(path, url).toString();\n",
              "    anchor.target = '_blank';\n",
              "    anchor.setAttribute('data-href', url + path);\n",
              "    anchor.textContent = text;\n",
              "    element.appendChild(anchor);\n",
              "  })(4040, \"/jobs/index.html\", \"https://localhost:4040/jobs/index.html\", window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Dataframe"
      ],
      "metadata": {
        "id": "TrOB1vrJQgHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType,StructField,StringType,IntegerType"
      ],
      "metadata": {
        "id": "fch5W_xlQkfs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Spark Joins Example\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "schema1=StructType([StructField(\"name\",StringType(),True),\n",
        "                    StructField(\"age\",IntegerType(),True),\n",
        "                    StructField(\"department\", StringType(), True)\n",
        "\n",
        "\n",
        "                  ] )"
      ],
      "metadata": {
        "id": "NXoMNq7MRKGf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema2=StructType([StructField(\"name\",StringType(),True),\n",
        "                    StructField(\"city\",StringType(),True)\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "UFztzGs_SMp9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data for Table"
      ],
      "metadata": {
        "id": "JT0Sx0FZTTE8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1=[(\"ansu\",32,\"Marketing\"),\n",
        "       (\"Abhi\",30,\"Salse\"),\n",
        "       (\"riya\",31,\"HR\")]\n",
        "\n",
        "data2=[(\"Abhi\",\"mumbai\"),\n",
        "       (\"riya\",\"pune\")\n",
        "\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "7hWxr5ZLTXYA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame 1\n",
        "df1 = spark.createDataFrame(data1, schema1)\n",
        "\n",
        "# Create DataFrame 2\n",
        "df2 = spark.createDataFrame(data2, schema2)\n",
        "\n",
        "df1.show()\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJTLj7auUfqV",
        "outputId": "8171e497-9b46-4c27-9046-afabc61e9b1a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+----------+\n",
            "|name|age|department|\n",
            "+----+---+----------+\n",
            "|ansu| 32| Marketing|\n",
            "|Abhi| 30|     Salse|\n",
            "|riya| 31|        HR|\n",
            "+----+---+----------+\n",
            "\n",
            "+----+------+\n",
            "|name|  city|\n",
            "+----+------+\n",
            "|Abhi|mumbai|\n",
            "|riya|  pune|\n",
            "+----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Left joins"
      ],
      "metadata": {
        "id": "WQfBzYCGUs5d"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = df1.join(df2 , on=[\"name\"], how = \"left\")\n",
        "a.show()\n",
        "\n",
        "a = df1.join(df2 , df1.name == df2.name, how = \"left\")\n",
        "a.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wvo9U-pzU66v",
        "outputId": "fb4b48a1-b4a3-4125-a1d0-b0a8ecf1363c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+----------+------+\n",
            "|name|age|department|  city|\n",
            "+----+---+----------+------+\n",
            "|ansu| 32| Marketing|  NULL|\n",
            "|riya| 31|        HR|  pune|\n",
            "|Abhi| 30|     Salse|mumbai|\n",
            "+----+---+----------+------+\n",
            "\n",
            "+----+---+----------+----+------+\n",
            "|name|age|department|name|  city|\n",
            "+----+---+----------+----+------+\n",
            "|ansu| 32| Marketing|NULL|  NULL|\n",
            "|riya| 31|        HR|riya|  pune|\n",
            "|Abhi| 30|     Salse|Abhi|mumbai|\n",
            "+----+---+----------+----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.createOrReplaceTempView(\"table1\")\n",
        "df2.createOrReplaceTempView(\"table2\")"
      ],
      "metadata": {
        "id": "HhExgXfgVLJU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b=spark.sql(\"select * from table1 left join table2 on table1.name=table2.name\")\n",
        "b.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wltcr-OiWvki",
        "outputId": "7ba13773-a436-4de9-9cc2-0862fd233a03"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+----------+----+------+\n",
            "|name|age|department|name|  city|\n",
            "+----+---+----------+----+------+\n",
            "|ansu| 32| Marketing|NULL|  NULL|\n",
            "|riya| 31|        HR|riya|  pune|\n",
            "|Abhi| 30|     Salse|Abhi|mumbai|\n",
            "+----+---+----------+----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=df1.join(df2,df1.name==df2.name,how=\"right\")\n",
        "a.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6VmFJSSXket",
        "outputId": "2d4966aa-6800-4a5d-ab46-70d33fc311bc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+----------+----+------+\n",
            "|name|age|department|name|  city|\n",
            "+----+---+----------+----+------+\n",
            "|Abhi| 30|     Salse|Abhi|mumbai|\n",
            "|riya| 31|        HR|riya|  pune|\n",
            "+----+---+----------+----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=df1.join(df2,df1.name==df2.name,how=\"inner\")\n",
        "a.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fctwWf7EYWAw",
        "outputId": "ba1a39a7-c720-405f-8d83-56537a288eb1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+----------+----+------+\n",
            "|name|age|department|name|  city|\n",
            "+----+---+----------+----+------+\n",
            "|Abhi| 30|     Salse|Abhi|mumbai|\n",
            "|riya| 31|        HR|riya|  pune|\n",
            "+----+---+----------+----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = df1.join(df2 , df1.name == df2.name, how = \"outer\")\n",
        "a.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gScpoZP0Yosa",
        "outputId": "a22f790d-2bff-4471-da77-d76f14dd24d6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+----------+----+------+\n",
            "|name|age|department|name|  city|\n",
            "+----+---+----------+----+------+\n",
            "|Abhi| 30|     Salse|Abhi|mumbai|\n",
            "|ansu| 32| Marketing|NULL|  NULL|\n",
            "|riya| 31|        HR|riya|  pune|\n",
            "+----+---+----------+----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = df1.join(df2 , df1.name == df2.name, how = \"cross\")\n",
        "a.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q02XUKZSYziM",
        "outputId": "0ccaad72-2346-4565-824b-0ff0f51343bd"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+----------+----+------+\n",
            "|name|age|department|name|  city|\n",
            "+----+---+----------+----+------+\n",
            "|Abhi| 30|     Salse|Abhi|mumbai|\n",
            "|riya| 31|        HR|riya|  pune|\n",
            "+----+---+----------+----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = df1.join(df2 , df1.name == df2.name, how = \"left_semi\")\n",
        "a.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERbA0ZZ7Y9wO",
        "outputId": "d568c064-d365-4119-d98b-84a91d0dd30f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+----------+\n",
            "|name|age|department|\n",
            "+----+---+----------+\n",
            "|Abhi| 30|     Salse|\n",
            "|riya| 31|        HR|\n",
            "+----+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = df1.join(df2 , df1.name == df2.name, how = \"left\")\n",
        "a.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXahUItWZHTc",
        "outputId": "91979e27-6482-46ea-ca0c-6b4994485a9f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+----------+----+------+\n",
            "|name|age|department|name|  city|\n",
            "+----+---+----------+----+------+\n",
            "|ansu| 32| Marketing|NULL|  NULL|\n",
            "|riya| 31|        HR|riya|  pune|\n",
            "|Abhi| 30|     Salse|Abhi|mumbai|\n",
            "+----+---+----------+----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = df1.join(df2 , df1.name == df2.name, how = \"left_anti\")\n",
        "a.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLFLCna8ZWZ8",
        "outputId": "f2dade32-32cb-4d0a-f693-a93aafbc728b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+----------+\n",
            "|name|age|department|\n",
            "+----+---+----------+\n",
            "|ansu| 32| Marketing|\n",
            "+----+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.show()\n",
        "\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydvYdaSXZdmR",
        "outputId": "1fbd8ccd-c206-40df-ca3e-1f8a28d2169b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+----------+\n",
            "|name|age|department|\n",
            "+----+---+----------+\n",
            "|ansu| 32| Marketing|\n",
            "|Abhi| 30|     Salse|\n",
            "|riya| 31|        HR|\n",
            "+----+---+----------+\n",
            "\n",
            "+----+------+\n",
            "|name|  city|\n",
            "+----+------+\n",
            "|Abhi|mumbai|\n",
            "|riya|  pune|\n",
            "+----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df1.orderBy(df1.department) # Show output in Ascending Order"
      ],
      "metadata": {
        "id": "A89xA3UuZsrG"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.collect()\n",
        "df1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8TR0FUiZvY4",
        "outputId": "5d527754-2aef-470d-dd9c-cfe9903321be"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+----------+\n",
            "|name|age|department|\n",
            "+----+---+----------+\n",
            "|riya| 31|        HR|\n",
            "|ansu| 32| Marketing|\n",
            "|Abhi| 30|     Salse|\n",
            "+----+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C8LQWtTYWlSA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}